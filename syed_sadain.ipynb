{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4uDtuSTB0pb",
        "outputId": "8e581737-ff0a-4c2c-9f4d-929e3aaafa1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root folder created at: /content/ds_Syed_Sadain\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IAfLZwu6rJzyWKgBToqwSmmVYU6VbjVs\n",
            "To: /content/ds_Syed_Sadain/csv_files/historical_trader_raw\n",
            "100%|██████████| 47.5M/47.5M [00:00<00:00, 201MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PgQC0tO8XN-wqkNyghWc_-mnrYv_nhSf\n",
            "To: /content/ds_Syed_Sadain/csv_files/fear_greed_raw.csv\n",
            "100%|██████████| 90.8k/90.8k [00:00<00:00, 62.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trader file: /content/ds_Syed_Sadain/csv_files/daily_with_sentiment.csv\n",
            "Sentiment file: /content/ds_Syed_Sadain/csv_files/fear_greed_raw.csv\n",
            "Mann-Whitney U test (PnL Sum): U=2949.0, p=0.5355361942691219\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        13\n",
            "           1       1.00      1.00      1.00        34\n",
            "\n",
            "    accuracy                           1.00        47\n",
            "   macro avg       1.00      1.00      1.00        47\n",
            "weighted avg       1.00      1.00      1.00        47\n",
            "\n",
            "ROC AUC: 1.0\n",
            "\n",
            "All outputs saved in: /content/ds_Syed_Sadain/outputs\n"
          ]
        }
      ],
      "source": [
        "# =======================================\n",
        "# FINAL COMPLETE ASSIGNMENT SOLUTION CODE\n",
        "# =======================================\n",
        "\n",
        "# Step 0: Install required libraries\n",
        "!pip install --quiet gdown seaborn scikit-learn scipy matplotlib pandas\n",
        "\n",
        "# Step 1: Setup folders\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "candidate_name = \"Syed_Sadain\"\n",
        "root = Path(f\"/content/ds_{candidate_name}\")\n",
        "folders = [root, root / \"csv_files\", root / \"outputs\"]\n",
        "for f in folders:\n",
        "    f.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Root folder created at:\", root)\n",
        "\n",
        "# Step 2: Download datasets from Google Drive\n",
        "import gdown\n",
        "\n",
        "csv_dir = root / \"csv_files\"\n",
        "trader_id = \"1IAfLZwu6rJzyWKgBToqwSmmVYU6VbjVs\"\n",
        "sentiment_id = \"1PgQC0tO8XN-wqkNyghWc_-mnrYv_nhSf\"\n",
        "\n",
        "trader_out = csv_dir / \"historical_trader_raw\"\n",
        "sentiment_out = csv_dir / \"fear_greed_raw.csv\"\n",
        "\n",
        "gdown.download(f\"https://drive.google.com/uc?id={trader_id}\", str(trader_out), quiet=False)\n",
        "gdown.download(f\"https://drive.google.com/uc?id={sentiment_id}\", str(sentiment_out), quiet=False)\n",
        "\n",
        "# Step 3: Unzip if needed\n",
        "import zipfile\n",
        "\n",
        "files_in_dir = list(csv_dir.iterdir())\n",
        "zips = [f for f in files_in_dir if f.suffix.lower() == \".zip\"]\n",
        "if zips:\n",
        "    for z in zips:\n",
        "        with zipfile.ZipFile(z, 'r') as zip_ref:\n",
        "            zip_ref.extractall(csv_dir)\n",
        "    print(\"Extracted:\", zips)\n",
        "\n",
        "# Step 4: Load CSVs\n",
        "import pandas as pd\n",
        "\n",
        "csvs = list(csv_dir.glob(\"*.csv\"))\n",
        "df_sent = pd.read_csv(sentiment_out)\n",
        "\n",
        "df_trader = None\n",
        "trader_path = None\n",
        "for f in csvs:\n",
        "    if f != sentiment_out:\n",
        "        if df_trader is None:\n",
        "            df_trader = pd.read_csv(f, low_memory=False)\n",
        "            trader_path = f\n",
        "        else:\n",
        "            if f.stat().st_size > trader_path.stat().st_size:\n",
        "                df_trader = pd.read_csv(f, low_memory=False)\n",
        "                trader_path = f\n",
        "\n",
        "if trader_path is None:\n",
        "    trader_path = trader_out\n",
        "    df_trader = pd.read_csv(trader_out, low_memory=False)\n",
        "\n",
        "print(\"Trader file:\", trader_path)\n",
        "print(\"Sentiment file:\", sentiment_out)\n",
        "\n",
        "# Step 5: Clean column names\n",
        "def clean_cols(df):\n",
        "    df = df.copy()\n",
        "    df.columns = (df.columns\n",
        "                  .str.strip()\n",
        "                  .str.replace(\" \", \"_\")\n",
        "                  .str.replace(\"-\", \"_\")\n",
        "                  .str.replace(\".\", \"\")\n",
        "                  .str.lower())\n",
        "    return df\n",
        "\n",
        "df_trader = clean_cols(df_trader)\n",
        "df_sent = clean_cols(df_sent)\n",
        "\n",
        "# Step 6: Parse dates\n",
        "time_cols = [c for c in df_trader.columns if \"time\" in c or \"date\" in c or \"timestamp\" in c]\n",
        "df_trader[time_cols[0]] = pd.to_datetime(df_trader[time_cols[0]], errors='coerce', utc=True)\n",
        "df_trader['trade_date'] = df_trader[time_cols[0]].dt.date\n",
        "\n",
        "date_cols = [c for c in df_sent.columns if \"date\" in c]\n",
        "df_sent[date_cols[0]] = pd.to_datetime(df_sent[date_cols[0]], errors='coerce').dt.date\n",
        "df_sent = df_sent.rename(columns={date_cols[0]: \"date\"})\n",
        "\n",
        "if \"classification\" not in df_sent.columns:\n",
        "    for c in df_sent.columns:\n",
        "        if df_sent[c].nunique() < 10:\n",
        "            df_sent = df_sent.rename(columns={c: \"classification\"})\n",
        "            break\n",
        "\n",
        "# Step 7: Daily aggregates with flexible column detection\n",
        "pnl_col = next((c for c in df_trader.columns if \"pnl\" in c or \"profit\" in c), None)\n",
        "size_col = next((c for c in df_trader.columns if \"size\" in c or \"qty\" in c), None)\n",
        "leverage_col = next((c for c in df_trader.columns if \"leverage\" in c), None)\n",
        "account_col = next((c for c in df_trader.columns if \"account\" in c), None)\n",
        "symbol_col = next((c for c in df_trader.columns if any(x in c for x in [\"symbol\",\"pair\",\"instrument\",\"ticker\"])), None)\n",
        "\n",
        "for col in [pnl_col, size_col, leverage_col]:\n",
        "    if col:\n",
        "        df_trader[col] = pd.to_numeric(df_trader[col], errors='coerce')\n",
        "\n",
        "group = df_trader.groupby(df_trader['trade_date'])\n",
        "daily = pd.DataFrame()\n",
        "daily['num_trades'] = group.size()\n",
        "\n",
        "if size_col:\n",
        "    daily['volume'] = group[size_col].sum()\n",
        "if pnl_col:\n",
        "    daily['pnl_sum'] = group[pnl_col].sum()\n",
        "    daily['pnl_mean'] = group[pnl_col].mean()\n",
        "    daily['pnl_median'] = group[pnl_col].median()\n",
        "if leverage_col:\n",
        "    daily['leverage_mean'] = group[leverage_col].mean()\n",
        "if account_col:\n",
        "    daily['unique_accounts'] = group[account_col].nunique()\n",
        "if symbol_col:\n",
        "    daily['unique_symbols'] = group[symbol_col].nunique()\n",
        "if pnl_col:\n",
        "    daily['win_rate'] = group.apply(lambda x: (x[pnl_col] > 0).sum(), include_groups=False) / daily['num_trades']\n",
        "\n",
        "daily = daily.reset_index().rename(columns={'trade_date': 'date'})\n",
        "daily.to_csv(csv_dir / \"daily_aggregates.csv\", index=False)\n",
        "\n",
        "# Step 8: Merge with sentiment\n",
        "daily['date'] = pd.to_datetime(daily['date']).dt.date\n",
        "df_sent['date'] = pd.to_datetime(df_sent['date']).dt.date\n",
        "merged = pd.merge(daily, df_sent[['date', 'classification']], on='date', how='left')\n",
        "merged['classification'] = merged['classification'].ffill().bfill()\n",
        "merged.to_csv(csv_dir / \"daily_with_sentiment.csv\", index=False)\n",
        "\n",
        "# Step 9: Visualization (outputs folder guaranteed)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "outputs_dir = root / \"outputs\"\n",
        "outputs_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.boxplot(x='classification', y='pnl_sum', data=merged)\n",
        "plt.title(\"Daily PnL Sum by Sentiment\")\n",
        "plt.savefig(outputs_dir / \"pnl_by_sentiment.png\")\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x='classification', y='win_rate', data=merged)\n",
        "plt.title(\"Win Rate by Sentiment\")\n",
        "plt.savefig(outputs_dir / \"winrate_by_sentiment.png\")\n",
        "plt.close()\n",
        "\n",
        "# Step 10: Statistical tests\n",
        "from scipy import stats\n",
        "greed = merged[merged['classification'].str.lower().str.contains(\"greed\")]\n",
        "fear = merged[merged['classification'].str.lower().str.contains(\"fear\")]\n",
        "\n",
        "u_stat, p_val = stats.mannwhitneyu(\n",
        "    greed['pnl_sum'].dropna(),\n",
        "    fear['pnl_sum'].dropna(),\n",
        "    alternative='two-sided'\n",
        ")\n",
        "print(f\"Mann-Whitney U test (PnL Sum): U={u_stat}, p={p_val}\")\n",
        "\n",
        "# Step 11: Simple Model - only using available features\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "merged['profitable_day'] = (merged['pnl_sum'] > 0).astype(int)\n",
        "desired_features = ['num_trades','volume','leverage_mean','win_rate','unique_accounts']\n",
        "features = [f for f in desired_features if f in merged.columns]\n",
        "\n",
        "if len(features) == 0:\n",
        "    raise ValueError(\"No valid numeric features found for modelling.\")\n",
        "\n",
        "df_model = merged.dropna(subset=features + ['profitable_day'])\n",
        "X = df_model[features]\n",
        "y = df_model['profitable_day']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_sc = scaler.fit_transform(X_train)\n",
        "X_test_sc = scaler.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_sc, y_train)\n",
        "y_pred = clf.predict(X_test_sc)\n",
        "y_prob = clf.predict_proba(X_test_sc)[:, 1]\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
        "print(\"\\nAll outputs saved in:\", outputs_dir)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v2kin7zNHO06"
      }
    }
  ]
}